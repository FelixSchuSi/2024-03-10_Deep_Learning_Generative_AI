{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7rKJtvht7y3"
      },
      "source": [
        "# Intro to TensorFlow: MNIST Logistic Regression Classifier\n",
        "\n",
        "Checked 25.02.24 GPaa√ü\n",
        "\n",
        "A detailed introduction to tensorflow is [here](https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/).\n",
        "\n",
        "First we have to load a number of libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "at74TKcot7y5"
      },
      "outputs": [],
      "source": [
        "import os, sys, math\n",
        "import numpy as np                             # library for vector, matrix, tensor operations\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt                # plotting library\n",
        "import pandas as pd                            # data handling library\n",
        "from IPython.display import display, Markdown  # for formatting answers to questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sTLAREot7y6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf                        # main tensorflow library\n",
        "from tensorflow import keras                   # keras on top of tensorflow\n",
        "from keras.models import Sequential, clone_model\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "print(\"python version =\",sys.version_info)      # check the version of python\n",
        "print(\"tensorflow version:\", tf.__version__)    # check the version of tensorflow\n",
        "print(\"Tensorflow compute devices (CPU, GPU): \")\n",
        "for dv in tf.config.list_physical_devices():\n",
        "    print(\"\\t\",dv)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`print_mat`: pretty-print a matrix or dataframe"
      ],
      "metadata": {
        "id": "V1uOVL3BgvjI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W8P46ORt7zB",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "def print_mat(x, title=\"\", prtDim=True, max_rows=10, max_columns=10, precision=3, doRound=True,index=None, rowNames=None, colNames=None ):\n",
        "    \"\"\" use pandas display to print a dataframe\n",
        "        title: to be printed\n",
        "        max_rows: number or None\n",
        "        max_columns: number or None\n",
        "        precision: number\n",
        "        doRound: True  perform rounding (avoid E notation)\n",
        "        index: None  row names\n",
        "        columns: None column names\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import tensorflow as tf\n",
        "    import numpy as np\n",
        "    with pd.option_context('display.max_rows', max_rows, 'display.max_columns', max_columns, 'display.precision',precision):\n",
        "        # pd.options.display.max_columns = None\n",
        "        if tf.is_tensor(x):\n",
        "            x = x.numpy()\n",
        "        if doRound:\n",
        "            x = np.round(x,decimals=precision)\n",
        "        if title!=\"\":\n",
        "            if prtDim:\n",
        "                print(title,x.shape)\n",
        "            else:\n",
        "                print(title,x.shape)\n",
        "        display(pd.DataFrame(x,index=rowNames, columns=colNames))     # use smaller font\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function resets all random generators to a given state  $\\longrightarrow$ an **identical** stream of random numbers is generated."
      ],
      "metadata": {
        "id": "wM3Q0VSqkUA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random as python_random\n",
        "def reset_seeds(num):\n",
        "  \"\"\" reset random number generators \"\"\"\n",
        "  np.random.seed(num)\n",
        "  python_random.seed(num)\n",
        "  tf.random.set_seed(num+1)"
      ],
      "metadata": {
        "id": "y6wMGrsi5ksh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuEW1jkxt7zJ"
      },
      "source": [
        "## Logistic Regression for MNIST Data\n",
        "\n",
        "### Read the MNIST Data\n",
        "\n",
        "**Task**: assign each $28\\times28$ pixel image to one of the digits  0,....,9.\n",
        "\n",
        "The data has the following form\n",
        "* input matrix $x$ of 60000 rows and 784 columns. Each row represents the image of a digit.\n",
        "* output value $y$ of length 60000 rows is the class index of the corresponding input.\n",
        "\n",
        "In addition there are 10000 test examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJjfb6dyt7zJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "print(\"x_train.shape\",x_train.shape,\"\\ty_train.shape\",y_train.shape)\n",
        "print(\"x_test.shape\",x_test.shape,\"\\ty_test.shape\",y_test.shape)\n",
        "xx=x_train\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVdvh7lqt7zJ"
      },
      "source": [
        "Print input and output of one example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bMACfv9t7zL"
      },
      "outputs": [],
      "source": [
        "### just for visualization ###\n",
        "itm = 7   # example to print\n",
        "print(\"y_train[\"+str(itm)+\"] =\",y_train[itm])\n",
        "#print(\"x_train[itm,]=\",x_train[itm,])\n",
        "df = pd.DataFrame(xx[itm,])\n",
        "pd.options.display.max_columns = None  # no column break\n",
        "print_mat(df,\"x_train[\"+str(itm)+\"] =\", max_columns=None, max_rows=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmpErSKQt7zL"
      },
      "outputs": [],
      "source": [
        "### just for visualization ###\n",
        "def showDigit(itm):\n",
        "    x1=xx[itm]\n",
        "    xx1 = np.array(x1, dtype='uint8') # array of 8-bits pixels\n",
        "    xx1 = xx1.reshape((28, 28))        # 28 x 28 array (2-dimensional array)\n",
        "    print(\"y_train[\"+str(itm)+\"]=\",y_train[itm])\n",
        "    print(\"x_train[\"+str(itm)+\"]=\")\n",
        "\n",
        "    plt.imshow(xx1, cmap='gray')\n",
        "    plt.show()\n",
        "showDigit(7)\n",
        "showDigit(1)\n",
        "showDigit(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guDKg6tkt7zL"
      },
      "source": [
        "### Logistic Regression Classifier with MNIST Data\n",
        "\n",
        "We again use Keras to define the model. The input has a dimension of $60000\\times28\\times28$.\n",
        "It has two layers:\n",
        "* First layer creates a vector of length $784$ from the $28\\times28$ pixel input matrix. <br> The output has dimension $60000\\times784$.\n",
        "* The second layer computes the probabilities of classes by $prb=\\text{softmax}(x*A+b)$.\n",
        "  <br> The output has a dimension of $60000\\times10$. Each row is a probability vector."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds(42)   ## reproducible random parameters"
      ],
      "metadata": {
        "id": "O7Kr71SRagZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEHpTFV_t7zL"
      },
      "outputs": [],
      "source": [
        "model0 = Sequential([\n",
        "  Flatten(input_shape=(28, 28)),  # function: convert 28x28 matrix to vector x\n",
        "  Dense(10,activation='softmax')  # function: out = softmax(A2*hid +b2)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2YBTCCst7zM"
      },
      "source": [
        "This model is a function, which can be applied to the training data.\n",
        "\n",
        "The result is a probability vector of length 10 for each input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNnmI1Ept7zM"
      },
      "outputs": [],
      "source": [
        "prb = model0(x_train)   # application to data requires random generation of parameters\n",
        "print_mat(prb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CbzKeDbt7zM"
      },
      "source": [
        "#### Loss function\n",
        "As before define a **loss function**: <br>\n",
        "The log of probability of the whole training set $(x_1,y_1),\\ldots,(x_n,y_n)$.\n",
        "$$ loss(w) =  -\\log p(y_1|x_1,w)-\\ldots- \\log p(y_n|x_n,w)$$\n",
        "where $p(y_i|x_i)$ is the probability of class $y_i$ computed for input $x_i$ with the current parameters $w$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGWCcmhMt7zN"
      },
      "outputs": [],
      "source": [
        "loss_fn = SparseCategoricalCrossentropy(from_logits=False)  # -log(p(y_iobs)) probability of observed digit, predicted from\n",
        "loss_fn(y_train, prb).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoXBxoa5t7zN"
      },
      "source": [
        "#### Optimizer Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-hoyOpFt7zN"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)  # use Adam optimizer\n",
        "model0.compile(optimizer = optimizer, # optimization method as string or optimizer object. alternative is sgd\n",
        "              loss = loss_fn,         # loss function\n",
        "              metrics = ['accuracy']) # for accuracy computation on test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_3d_ESrt7zN"
      },
      "source": [
        "The three most common loss functions are:\n",
        "\n",
        "-    `binary_crossentropy` for binary classification.\n",
        "-    `categorical_crossentropy` for multi-class classification\n",
        "-    `sparse_categorical_crossentropy` for multi-class classification (using an approximation).\n",
        "-    `mse` (mean squared error) for regression to predict a continuos variable.\n",
        "\n",
        "A list of loss functions is given [here](https://www.tensorflow.org/api_docs/python/tf/keras/losses). A list of optimizers is given [here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). A list of metrics to measure prediction quality is [here](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJPWRcrPt7zN"
      },
      "source": [
        "### Training\n",
        "Fitting the model requires that you first select the training configuration, such as\n",
        "* the number of **epochs** (loops through the training dataset) and\n",
        "* the **batch size** (number of samples in an epoch used to estimate model error).\n",
        "\n",
        "Training applies the chosen optimization algorithm to minimize the chosen loss function and updates the model parameters using the backpropagation of error algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WnPLZ8Lt7zO"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "t0 = time.time()\n",
        "model0.fit(x_train,                             # training set input\n",
        "           y_train,                             # training set output\n",
        "           batch_size=60000,                    # number of training instances for optimization: all\n",
        "           validation_data=(x_test, y_test),    # validation set (optional)\n",
        "           epochs=150,                          # number of passes through data\n",
        "           verbose=2)                           # amount of output: 0-2\n",
        "print(\"used {0:.1f} sec\".format(time.time()-t0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4d0tHzNt7zO"
      },
      "source": [
        "While fitting the model, a progress bar will summarize the status of each epoch and the overall training process. This can be simplified to a simple report of model performance each epoch by setting the `verbose` argument to 2. All output can be turned off during training by setting `verbose` to 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnjtjCict7zO"
      },
      "source": [
        "### Plot the learning curve\n",
        "\n",
        "Function to plot loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plot_hist(hist):\n",
        "    fig, ax = plt.subplots(1, 2,figsize=(8,3.3))\n",
        "    colormap = np.array(['r', 'g'])\n",
        "    ax[0].title.set_text('Loss')\n",
        "    ax[0].plot(hist['loss'], label='train loss')\n",
        "    ax[0].plot(hist['val_loss'], label='validation loss')\n",
        "    ax[0].set_ylim([0, max(max(hist['loss']), max(hist['val_loss']))])\n",
        "    #ax[0].scatter(xx[:,0],xx[:,1], c=colormap[yy.astype(int)])\n",
        "    ax[0].legend()\n",
        "    ax[0].set_xlabel('epoch')\n",
        "    #ax[0].set_ylabel('loss')\n",
        "    ax[1].title.set_text('Accuracy')\n",
        "    ax[1].plot(hist['accuracy'], label='train accuracy')\n",
        "    ax[1].plot(hist['val_accuracy'], label='validation accuracy')\n",
        "    ax[1].set_ylim([min(min(hist['accuracy']), min(hist['val_accuracy'])),1.0])\n",
        "    ax[1].legend()\n",
        "    ax[1].set_xlabel('epoch')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_7PGVyu99mob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG6Ek6J0t7zO"
      },
      "outputs": [],
      "source": [
        "plot_hist(model0.history.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEIp2OPqt7zP"
      },
      "source": [
        "## Model with smaller batch_size\n",
        "\n",
        "Compute the gradient not for the whole training set but only for 64 randomly selected elements."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " <font color='red'>**Task 1:**</font>   \n",
        " We have a training set of $n=60000$ elements\n",
        "* The average gradient of the whole training set is $$avg= \\frac1n \\sum_{i=1}^n -\\frac{\\partial \\log p(y_i|x_i,w)}{\\partial w} $$\n",
        "* Assume $S$ is a random subset of $1,\\ldots,n$ containing $|S|$ elements. Then we define\n",
        "$$avg_S= \\frac1{|S|} \\sum_{i\\in S} -\\frac{\\partial \\log p(y_i|x_i,w)}{\\partial w} $$\n",
        "\n",
        "What is the expected value or average mean value of $avg_S$?\n",
        "\n",
        "What is the consequence for the gradient steps?"
      ],
      "metadata": {
        "id": "mEcWgRKzJUdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ans=\"\"\" \"\"\""
      ],
      "metadata": {
        "id": "PJjd4POPLlZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run next cell to get an answer."
      ],
      "metadata": {
        "id": "aFnDTi7GUpbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "display(Markdown(\n",
        "  rf\"\"\"\n",
        "Question 1:\n",
        "  * According to the law of large numbers the average of a sample of elements\n",
        "    from some distribution converges to the global average.<br>\n",
        "    Therefore the expected values of $avg$ and $avg_S$ are **equal**.\n",
        "\n",
        "  * The variance (mean square distance from the global average)\n",
        "    will be smaller for $avg$ than for $avg_S$.\n",
        "\n",
        "Question 2:\n",
        "  * Therefore the gradients for a step with $avg$ and $avg_S$ will point **on average** in the same direction.\n",
        "  * But the gradients of $avg_S$ will have a larger fluctuation around the global average.\n",
        "\"\"\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RqgSvLP4b75U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYolc6bRt7zP"
      },
      "outputs": [],
      "source": [
        "model1 = Sequential([\n",
        "  Flatten(input_shape=(28, 28)),  # function: convert 28x28 matrix to vector x\n",
        "  Dense(10,activation='softmax')  # function: out = softmax(A2*hid +b2)\n",
        "])\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "model1.compile(optimizer = 'adam',     # optimization method as string or optimizer object. alternative is sgd\n",
        "              loss = loss_fn,         # loss function\n",
        "              metrics = ['accuracy']) # for accuracy computation\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gpf0XSZ2t7zP"
      },
      "source": [
        "Memory footprint:\n",
        "* batchsize 60000: 60000*784 + 60000*1 = 47100000\n",
        "* batchsize 64: 64*784 + 64*1 = 50240"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_seeds(42)   ## reproducible random parameters"
      ],
      "metadata": {
        "id": "Ha-ELcgldYOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAblWaHct7zP"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "batch_size = 64\n",
        "epochs=10\n",
        "updates_per_epoch = x_train.shape[0]/64\n",
        "print(\"gradient updates_per_epoch\",updates_per_epoch,\"\\n\")\n",
        "\n",
        "model1.fit(x_train,                             # training set input\n",
        "           y_train,                             # training set output\n",
        "           batch_size=batch_size,               # number of training instances for optimization: 100\n",
        "           validation_data=(x_test, y_test),    # validation set (optional)\n",
        "           epochs=epochs,                       # number of passes through data\n",
        "           verbose=2)                           # amount of output: 0-2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOE-eEG-t7zQ"
      },
      "source": [
        "### Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMqi0rPdt7zQ"
      },
      "outputs": [],
      "source": [
        "plot_hist(model1.history.history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[0]"
      ],
      "metadata": {
        "id": "7VCDJ8QR0xZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'>**Task 2:**</font>   \n",
        " What is the number of gradient computations during the epochs?"
      ],
      "metadata": {
        "id": "h1ROme-seNgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run next cell to get an answer."
      ],
      "metadata": {
        "id": "Xq4XpMtqU5cU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "display(Markdown(\n",
        "  rf\"\"\"\n",
        "  * The number of gradient updates per iteration is {x_train.shape[0]}/{batch_size} = {math.floor(x_train.shape[0]/batch_size)}\n",
        "  * As we have  {epochs} epochs there are **{epochs*math.floor(x_train.shape[0]/batch_size)} gradient updates**.\n",
        "\"\"\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Lkm3ijRkeL3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EVq0AqVt7zQ"
      },
      "source": [
        "## Evaluation of the Model Performance\n",
        "The model.evaluate method checks the models performance, usually on a validation-set.\n",
        "\n",
        "The speed of model evaluation is proportional to the amount of data you want to use for the evaluation, although it is much faster than training as the model is not changed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYRnyuR9t7zQ"
      },
      "outputs": [],
      "source": [
        "performance=model1.evaluate(x_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27dd1VtPt7zR"
      },
      "source": [
        "Predict the model for a few examples. The probabilities of classes are usually near 1.0 or 0.0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS-kwbnBt7zR"
      },
      "outputs": [],
      "source": [
        "n=20\n",
        "yhat = model1.predict(x_test[:n])   # need a matrix with rows\n",
        "print_mat(yhat)\n",
        "print(\"arg.max = \",np.argmax(yhat,axis=1))\n",
        "print(\"y_test  = \",y_test[:n])\n",
        "print(np.argmax(yhat,axis=1) == y_test[:n])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbDlleEut7zR"
      },
      "source": [
        "## Alternative ways to specify a model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### By iteratively adding layers\n",
        "All layers form an execution sequence.\n",
        "\n",
        "Very similar to specifying layers as inputs to `Sequential`."
      ],
      "metadata": {
        "id": "FIpUZgHhWdi8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EETP2Md1t7zS"
      },
      "source": [
        "\n",
        "```\n",
        "model2 = Sequential()\n",
        "model2.add(layer1)     # add a layer\n",
        "model2.add(layer2)     # add another layer\n",
        "...\n",
        "model2.compile(optimizer= ..., loss= ...)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9p8CA91Kt7zS"
      },
      "outputs": [],
      "source": [
        "reset_seeds(42)   ## reproducible random parameters\n",
        "model2 = Sequential()\n",
        "model2.add(Flatten(input_shape=(28, 28)))           # convert 28x28 matrix to vector x\n",
        "model2.add(Dense(10, activation='softmax'))         # out = A2*hid +b2\n",
        "\n",
        "model2.compile(optimizer='adam',                    # string or optimizer. alternative is sgd\n",
        "              loss=SparseCategoricalCrossentropy(), # loss function\n",
        "              metrics=['accuracy'])                 # for accuracy computation\n",
        "model2.summary()\n",
        "model2.fit(x_train,                         # training set input\n",
        "           y_train,                          # training set output\n",
        "           batch_size=100,                   # number of training instances for each gradient computation: 100\n",
        "           validation_data=(x_test, y_test), # validation set (optional)\n",
        "           epochs=10,                        # number of passes through data\n",
        "           verbose=1)                        # amount of output: 0-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMoKyUhkt7zS"
      },
      "outputs": [],
      "source": [
        "performance=model2.evaluate(x_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### By using variables to communicate results\n",
        "\n",
        "* A variable can be input to several layers (operators).\n",
        "* An operator can produce several output variables\n",
        "* This allows to specify **complex connection graphs**.\n"
      ],
      "metadata": {
        "id": "r64Mt0ukWC8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "inp = tf.keras.Input(shape=inputDim) # input dim without first component\n",
        "layer1 = Layer1(hyperparams1)  # define a layer\n",
        "hid1 = layer1(inp)             # specify input / output variables\n",
        "\n",
        "layer2 = Layer2(hyperparams2)  # define another layer\n",
        "hid2 = layer2(hid1)            # specify inputs/ output variables\n",
        "\n",
        "model = tf.keras.Model(iputs=inp, outputs=hid2)  # define inputs, outputs\n",
        "model.compile(optimizer= ..., loss= ...)   \n",
        "```"
      ],
      "metadata": {
        "id": "mo_8dQ0Fd-yI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can be shortened to\n",
        "```\n",
        "inp = tf.keras.Input(shape=inputDim) # input dim without first component\n",
        "hid1 = Layer1(hyperparams1)(inp)   # define a layer & input, output\n",
        "\n",
        "hid2 = Layer2(hyperparams2)(hid1)  # define a layer & input, output\n",
        "\n",
        "model = tf.keras.Model(iputs=inp, outputs=hid2)  # define inputs, outputs\n",
        "model.compile(optimizer= ..., loss= ...)   `\n",
        "```"
      ],
      "metadata": {
        "id": "wjqity9LeHVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = tf.keras.Input(shape= x_train.shape[1:])  # input dim (without first dim)\n",
        "layer1 = Flatten()                        # define a layer\n",
        "hid1 = layer1(inp)                        # specify inputs / outputs\n",
        "\n",
        "layer3 = Dense(10, activation='softmax')     # define another layer\n",
        "hid2 = layer3(hid1)                       # specify inputs / outputs\n",
        "\n",
        "model3 = tf.keras.Model(inputs=inp, outputs=hid2)\n",
        "\n",
        "\n",
        "model3.compile(optimizer='adam',                    # string or optimizer. alternative is sgd\n",
        "              loss=SparseCategoricalCrossentropy(), # loss function\n",
        "              metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "px61WJ6xdPzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.fit(x_train,                         # training set input\n",
        "           y_train,                          # training set output\n",
        "           batch_size=100,                   # number of training instances for each gradient computation: 100\n",
        "           validation_data=(x_test, y_test), # validation set (optional)\n",
        "           epochs=10,                        # number of passes through data\n",
        "           verbose=1)                        # amount of output: 0-2"
      ],
      "metadata": {
        "id": "maJl8m6Aff6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance=model3.evaluate(x_test,  y_test, verbose=2)"
      ],
      "metadata": {
        "id": "sWiySoKsv2yw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "livereveal": {
      "scroll": "True",
      "start_slideshow_at": "selected",
      "theme": "simplePs",
      "transition": "zoom"
    },
    "nbpresent": {
      "slides": {
        "5d0ab039-9649-438a-9ea7-25c0a54307cf": {
          "id": "5d0ab039-9649-438a-9ea7-25c0a54307cf",
          "layout": "grid",
          "prev": null,
          "regions": {
            "5677b434-c42b-49ec-9c82-b0b6c0f24216": {
              "attrs": {
                "height": 0.4166666666666667,
                "pad": 0.01,
                "width": 0.9166666666666666,
                "x": 0.08333333333333333,
                "y": 0.08333333333333333
              },
              "content": {
                "cell": "42e8a721-8167-498f-bc9f-e81913335295",
                "part": "whole"
              },
              "id": "5677b434-c42b-49ec-9c82-b0b6c0f24216"
            },
            "dacdc962-390c-4b5c-a20b-6a4034c5ca0c": {
              "attrs": {
                "height": 0.4166666666666667,
                "pad": 0.01,
                "width": 0.9166666666666666,
                "x": 0.08333333333333333,
                "y": 0.5833333333333334
              },
              "id": "dacdc962-390c-4b5c-a20b-6a4034c5ca0c"
            }
          },
          "theme": null
        }
      },
      "themes": {
        "default": "68cbdb39-de1e-4cec-acd9-8e7df034b6d5",
        "theme": {
          "68cbdb39-de1e-4cec-acd9-8e7df034b6d5": {
            "id": "68cbdb39-de1e-4cec-acd9-8e7df034b6d5",
            "palette": {
              "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
                "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
                "rgb": [
                  252,
                  252,
                  252
                ]
              },
              "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
                "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
                "rgb": [
                  68,
                  68,
                  68
                ]
              },
              "50f92c45-a630-455b-aec3-788680ec7410": {
                "id": "50f92c45-a630-455b-aec3-788680ec7410",
                "rgb": [
                  155,
                  177,
                  192
                ]
              },
              "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
                "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
                "rgb": [
                  43,
                  126,
                  184
                ]
              },
              "efa7f048-9acb-414c-8b04-a26811511a21": {
                "id": "efa7f048-9acb-414c-8b04-a26811511a21",
                "rgb": [
                  25.118061674008803,
                  73.60176211453744,
                  107.4819383259912
                ]
              }
            },
            "rules": {
              "blockquote": {
                "color": "50f92c45-a630-455b-aec3-788680ec7410"
              },
              "code": {
                "font-family": "Anonymous Pro"
              },
              "h1": {
                "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
                "font-family": "Lato",
                "font-size": 8
              },
              "h2": {
                "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
                "font-family": "Lato",
                "font-size": 6
              },
              "h3": {
                "color": "50f92c45-a630-455b-aec3-788680ec7410",
                "font-family": "Lato",
                "font-size": 5.5
              },
              "h4": {
                "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
                "font-family": "Lato",
                "font-size": 5
              },
              "h5": {
                "font-family": "Lato"
              },
              "h6": {
                "font-family": "Lato"
              },
              "h7": {
                "font-family": "Lato"
              },
              "pre": {
                "font-family": "Anonymous Pro",
                "font-size": 4
              }
            },
            "text-base": {
              "font-family": "Merriweather",
              "font-size": 4
            }
          }
        }
      }
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "887px",
        "left": "0px",
        "right": "1548px",
        "top": "111px",
        "width": "212px"
      },
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}