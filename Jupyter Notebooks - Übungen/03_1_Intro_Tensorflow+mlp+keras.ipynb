{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BorASt16t7qy"
      },
      "source": [
        "# Introduction to TensorFlow: Multilayer Network\n",
        "checked 20.02.24 GPaaß  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saa6tijOt7qz"
      },
      "outputs": [],
      "source": [
        "import os, sys; #sys.path.insert(0, os.path.abspath('..'));  import hlp\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython.display import display, Markdown  # for formatting answers to questions\n",
        "print(\"tensorflow version:\", tf.__version__)    # check the version of tensorflow\n",
        "print(\"python version =\",sys.version_info)      # check the version of python\n",
        "print(\"Tensorflow compute devices (CPU, GPU)\")\n",
        "for dv in tf.config.list_physical_devices():\n",
        "    print(dv)\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell defines a print function `print_mat`for tensors."
      ],
      "metadata": {
        "id": "_n1Y7XkinVLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def print_mat(x, title=\"\", prtDim=True, max_rows=10, max_columns=10, precision=3, doRound=True,index=None, rowNames=None, colNames=None ):\n",
        "    \"\"\" use pandas display to print a dataframe\n",
        "        title: to be printed\n",
        "        max_rows: number or None\n",
        "        max_columns: number or None\n",
        "        precision: number\n",
        "        doRound: True  perform rounding (avoid E notation)\n",
        "        index: None  row names\n",
        "        columns: None column names\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import tensorflow as tf\n",
        "    import numpy as np\n",
        "    with pd.option_context('display.max_rows', max_rows, 'display.max_columns', max_columns, 'display.precision',precision):\n",
        "        # pd.options.display.max_columns = None\n",
        "        if tf.is_tensor(x):\n",
        "            x = x.numpy()\n",
        "        if doRound:\n",
        "            x = np.round(x,decimals=precision)\n",
        "        if title!=\"\":\n",
        "            if prtDim:\n",
        "                print(title,x.shape)\n",
        "            else:\n",
        "                print(title,x.shape)\n",
        "        display(pd.DataFrame(x,index=rowNames, columns=colNames))     # use smaller font\n"
      ],
      "metadata": {
        "id": "n2fSkkOm8gdv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWhZGJNGt7q1"
      },
      "source": [
        "## Data is MNIST or Fashion\n",
        "Read data:\n",
        "* if `use_MNIST = True` read the **MNIST** data of 28x28 grey-value images of digits in 10 classes.\n",
        "* if `use_MNIST = False` read the **Fashion** data of 28x28 grey-value images of clothes in 10 classes.\n",
        "\n",
        "\n",
        "\n",
        "**Target**: assign each $28\\times28$ pixel image to one of the classes  0,....,9.\n",
        "\n",
        "The data has the following form\n",
        "* input tensor $x$ of shape 60000x28x28 with 60000 images of size 28x28 of a digit.\n",
        "* output matrix $y$ of 60000x1 with 60000 observed digits.\n",
        "\n",
        "\n",
        "<!--- training data *mnist.train* contains 55000 images of digits, the validation data *mnist.validation* of 5000 images and the test data *mnist.test* of 10000 images. It is retrieved by  --->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3HOgi3Yt7q3"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.models import Sequential, clone_model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "use_MNIST = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bkmj_PUut7q4"
      },
      "outputs": [],
      "source": [
        "if use_MNIST:\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "    class_names = ['null', 'eins', 'zwei', 'drei', 'vier','fünf', 'sechs', 'sieben', 'acht', 'neun']\n",
        "else:\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "print(\"x_train.shape\",x_train.shape,\"\\ty_train.shape\",y_train.shape)\n",
        "print(\"x_test.shape\",x_test.shape,\"\\ty_test.shape\",y_test.shape)\n",
        "xx_train=x_train\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc0zxUQwt7q5"
      },
      "source": [
        "Read 5 examples and show their values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8jtDsXCt7q6"
      },
      "outputs": [],
      "source": [
        "itm = 4    # example to print\n",
        "print(\"y_train[\"+str(itm)+\"] =\",class_names[y_train[itm]])\n",
        "#print(\"x_train[itm,]=\",x_train[itm,])\n",
        "df = pd.DataFrame(xx_train[itm,])\n",
        "pd.options.display.max_columns = None  # no column break\n",
        "print_mat(df,\"x_train[\"+str(itm)+\"] =\", max_columns=None, max_rows=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afaHtWVZt7q7"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "iclass = y_train[itm]\n",
        "yhot1 = np.zeros(len(class_names))\n",
        "yhot1[iclass]=1\n",
        "x1=xx_train[itm]\n",
        "xx1 = np.array(x1, dtype='uint8') # array of 8-bits pixels\n",
        "xx1 = xx1.reshape((28, 28))        # 28 x 28 array (2-dimensional array)\n",
        "print(\"iclass[\",itm,\"]=\",class_names[iclass])\n",
        "print(\"yhot1[\",itm,\"]=\",yhot1)\n",
        "plt.imshow(xx1, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PUN42yRt7q-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,18))\n",
        "for i in range(25):\n",
        "    # define subplot\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    # plot raw pixel data\n",
        "\n",
        "    plt.title(class_names[y_train[i]])\n",
        "    plt.imshow(xx_train[i], cmap=plt.get_cmap('gray'))\n",
        "# show the figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UZifP8jt7q_"
      },
      "source": [
        "## Multi-Layer Neural Network with Tensorflow\n",
        "### The Data\n",
        "The data is a tensor with dimensions (60000, 28, 28).\n",
        "* The **first dimension** `x_train[i,*,*]`indexes the different examples of the training data. Here a pixel matrix of the image. <br>\n",
        "This is the **convention for all models**.\n",
        "* The second and the third dimension indicate the rows `x_train[i,j,*]` and columns `x_train[i,*,k]` of the `i`-th pixel matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Model\n",
        "<!---This is an adapted version of the tensorflow [tutorial](https://www.tensorflow.org/versions/r0.11/tutorials/mnist/beginners/index.html). --->\n",
        "\n",
        "We always process batches of $batchsize$ inputs-output pairs in parallel (e.g. $batchsize=64$). The example index is always the first dimension.\n",
        "The model  \n",
        "- flatten the pixel matrix to a vector $v$ <br>\n",
        "- transform $v$ with a fully connected nonlinear layer to a hidden vector `hid1` </br>\n",
        "$$ hid1 = \\text{tanh}(v*W1 +b1) $$\n",
        "- transform `hid1` with a fully connected linear layer, then transform by `softmax` to a probability vector `py`\n",
        " of the different classes (=digits). </br>\n",
        "$$ py = \\text{softmax}(hid1*W3 +b3) $$\n"
      ],
      "metadata": {
        "id": "tcdFGwPOZjQa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haomYka_t7rA"
      },
      "source": [
        "\n",
        "### Loss function\n",
        "\n",
        "* $x_i$ is the observed image, $y_i$ is the class index of the observed digit and $py_i$ the vector with all predicted class probabilities for $x_i$.\n",
        "* The **loss** for a single image - label pair $(x_i,y_i)$ is defined as\n",
        "$$  -  \\log(p(y_i|x_i,w)) >0 $$\n",
        "The loss is larger than 0 as the probability is smaller than 1.0.\n",
        "$$loss(w) = \\sum_{i=1}^n -  \\log(p(y_i|x_i,w)) $$\n",
        "* The loss is averaged over the image - label pairs of the minibatch in the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC7wOisat7rB"
      },
      "source": [
        "### Define the Model Architecture\n",
        "\n",
        "\n",
        "We use regularization by **L2-regularization** (weight decay):\n",
        "* `regularizers.l2(0.001)` means that every coefficient $w_i$ in the weight matrix of the layer will add $0.001 * w_i^2$ to the total loss of the network. Hence this coefficient is pulled to 0.0.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Oz-ku6bt7rB"
      },
      "outputs": [],
      "source": [
        "import random as python_random\n",
        "def reset_seeds(num):\n",
        "  \"\"\" reset random number generators \"\"\"\n",
        "  np.random.seed(num)\n",
        "  python_random.seed(num)\n",
        "  tf.random.set_seed(num+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyPFr09Rt7rC"
      },
      "outputs": [],
      "source": [
        "reset_seeds(17)\n",
        "nhid1 = 20      # number of hidden units layer 1: 200\n",
        "l2reg = 0.000   # 0.0\n",
        "batch_size = 64 # number of randomly selected elements for gradient computation\n",
        "\n",
        "model=Sequential()\n",
        "#Start defining the input tensor:\n",
        "#inpMatrix = keras.Input(x_train.shape[1:])    # A shape tuple (integers), not including the batch size.\n",
        "\n",
        "# ------ LAYER 1 ----------\n",
        "model.add(Flatten(input_shape=(28, 28))) # convert 28x28 matrix to vector x\n",
        "\n",
        "# ------ LAYER 2 ----------\n",
        "model.add(Dense(units=nhid1,                                 #create layer function\n",
        "                       activation='tanh',\n",
        "                       kernel_regularizer=keras.regularizers.l2(l2reg),  # 0.002\n",
        "                       kernel_initializer='he_normal'))\n",
        "\n",
        "# ------ LAYER 3 ----------\n",
        "\n",
        "model.add(Dense(units=10,\n",
        "                       kernel_initializer='he_normal',\n",
        "                       kernel_regularizer=keras.regularizers.l2(l2reg),    #0.002\n",
        "                       activation='softmax'))\n",
        "\n",
        "#define the model's input tensors and output tensors\n",
        "#model = keras.Model(inpMatrix, y_probs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **regularizer** aims to reduce the magnitude of parameters: lower value $\\rightarrow$ less regularization. You can evaluate the effect of different values."
      ],
      "metadata": {
        "id": "8TCmQAkxjXwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " <font color='blue'>**Task 1:**</font> What are the input and output dimensions of the different layers?"
      ],
      "metadata": {
        "id": "fpfkr0nefD3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim_layer1 = -1"
      ],
      "metadata": {
        "id": "0PgdbElQfDG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dim_layer1 = -1"
      ],
      "metadata": {
        "id": "UoEL9lbTe4lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dim_layer2 = -1"
      ],
      "metadata": {
        "id": "ZFb9V9Flfh9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dim_layer3 = -1"
      ],
      "metadata": {
        "id": "pEXc79ksfiUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Answer\n",
        "display(Markdown(\n",
        "   rf\"\"\"\n",
        "   `input_dim_layer1`:  =  {[batch_size,x_train.shape[1],x_train.shape[2]]} <br>\n",
        "   `output_dim_layer1`  =  {[batch_size,x_train.shape[1]*x_train.shape[2]]} <br>\n",
        "   `output_dim_layer2`  =  {[batch_size,nhid1]} <br>\n",
        "   `output_dim_layer3`  =  {[batch_size,10]} <br>\n",
        "\"\"\"))"
      ],
      "metadata": {
        "id": "ZWGyrfr-gOTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQXKR_pet7rC"
      },
      "source": [
        "\n",
        "\n",
        "Now we select optimizer and accuracy as monitoring value and configure the model for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVbfLgblt7rD"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),  # use loss - \\log(p(y_i|x_i,w))\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=0.1),     #stochastic gradient descent with r = learning rate\n",
        "              metrics=['accuracy'])                                  # apply acc or accuracy to vaidation data\n",
        "print(\"model.loss      = \",model.loss)\n",
        "print(\"model.optimizer = \",model.optimizer)\n",
        "print(\"model.metrics   = \",model.metrics)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4zS3ytNt7rD"
      },
      "source": [
        "### Training\n",
        "We use `model.fit`, which trains the model for a number of epochs.\n",
        "To fit the model, all we have to do is declare the batch size and number of epochs to train for, then pass in our training data.\n",
        "\n",
        "You can monitor the GPU acivity in the Terninal with `watch nvidia-smi`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tguHTT6t7rD"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "model.fit(x_train,                           # input examples   60000 x 28 x 28\n",
        "          y_train,                           # output examples  60000 x 1\n",
        "          batch_size = batch_size,           # number of examples for gradient computation\n",
        "          validation_data=(x_test, y_test),  # data to compute accuracy metric\n",
        "          epochs=20,                         # number of passes through data\n",
        "          verbose=2)                         # how much output (0-2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5zBMr8st7rE"
      },
      "source": [
        "### Evaluation & Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`plot_history` function for plotting the history: loss and accuracy for validation"
      ],
      "metadata": {
        "id": "BTmrcdRMrdz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4kC4hVOt7rE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "def plot_history(hist):\n",
        "    fig, ax = plt.subplots(1, 2,figsize=(8,3.3))\n",
        "    colormap = np.array(['r', 'g'])\n",
        "    ax[0].title.set_text('Loss')\n",
        "    ax[0].plot(hist['loss'], label='train loss')\n",
        "    ax[0].plot(hist['val_loss'], label='validation loss')\n",
        "    ax[0].set_ylim([0, max(max(hist['loss']), max(hist['val_loss']))])\n",
        "    #ax[0].scatter(xx[:,0],xx[:,1], c=colormap[yy.astype(int)])\n",
        "    ax[0].legend()\n",
        "    ax[0].set_xlabel('epoch')\n",
        "    #ax[0].set_ylabel('loss')\n",
        "    ax[1].title.set_text('Accuracy')\n",
        "    ax[1].plot(hist['accuracy'], label='train accuracy')\n",
        "    ax[1].plot(hist['val_accuracy'], label='validation accuracy')\n",
        "    ax[1].set_ylim([min(min(hist['accuracy']), min(hist['val_accuracy'])),1.0])\n",
        "    ax[1].legend()\n",
        "    ax[1].set_xlabel('epoch')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(model.history.history)\n"
      ],
      "metadata": {
        "id": "IWkHTpYX1C1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7hfml1lt7rE"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"vali loss, vali acc \",score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54aiD2Prt7rF"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_test[:9])\n",
        "print_mat(y_pred)\n",
        "y_test[:9]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " <font color='blue'>**Task 2:**</font>\n",
        " Hyperparameter Search. <br>\n",
        " Evaluate different versions of the model to find the configuration with highest accuracy. Always reset random number generator, e.g. `reset_seeds(17)`!\n",
        "\n",
        "\n",
        " * Change number of layers: e.g. `nlayer = ` 3,4\n",
        " * Change number of hidden units, e.g. 20, `nhid =` 100, 400.\n",
        " * Change the regularization, e.g. `l2reg =`0, 0.001, 0.005\n",
        " * Change the batch size, e.g. `batch_size =` 64, 512, 2048\n",
        "\n",
        " Generate a new line for each configuration.\n",
        "\n",
        " What is your **best configuration**?"
      ],
      "metadata": {
        "id": "UeQ3AKw2pJJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset: fill the following matrix\n",
        "colnames = ['nlayer', 'nhid', 'l2reg', 'batch_size', 'val_loss', 'val_acc']\n",
        "res= [\n",
        "       [3, 20, 0.0, 64, 0.1436, 0.9552],\n",
        "       [0, 20, 0.0, 64, 0.0000, 0.0000],\n",
        "       [0, 20, 0.0, 64, 0.0000, 0.0000],\n",
        "       [0, 20, 0.0, 64, 0.0000, 0.0000],\n",
        "       [0, 20, 0.0, 64, 0.0000, 0.0000],\n",
        "       [0, 20, 0.0, 64, 0.0000, 0.0000],\n",
        "     ]\n",
        "df = pd.DataFrame(res, columns = colnames)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "45h731hUoA2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**Task 3:**</font> Repeat the hypertext search for the `fashion` dataset: <br>\n",
        "`use_MNIST = True`"
      ],
      "metadata": {
        "id": "8jql0BM5N9MV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fashio dataset: fill the following matrix\n",
        "colnames = ['nlayer', 'nhid', 'l2reg', 'batch_size', 'val_loss', 'val_acc']\n",
        "res= [\n",
        "       [3, 20, 0.0, 64, 0.1436, 0.9552],\n",
        "       [0, 20, 0.0, 64, 0.0000, 0.0000],\n",
        "       [0, 20, 0.0, 64, 0.0000, 0.0000],\n",
        "       [0, 20, 0.0, 64, 0.0000, 0.0000],\n",
        "       [0, 20, 0.0, 64, 0.0000, 0.0000],\n",
        "       [0, 20, 0.0, 64, 0.0000, 0.0000],\n",
        "     ]\n",
        "df = pd.DataFrame(res, columns = colnames)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "dRpREwZTOaVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szdinNyCt7rG"
      },
      "source": [
        "## Advanced topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOh1J-Rft7rG"
      },
      "source": [
        "### How to Halt Training at the Right Time With Early Stopping\n",
        "Neural networks are challenging to train.\n",
        "\n",
        "Too little training and the model is underfit; too much training and the model overfits the training dataset. Both cases result in a model that is less effective than it could be.\n",
        "\n",
        "One approach to solving this problem is to use **early stopping**. This involves monitoring the loss on the training dataset and a validation dataset (a subset of the training set not used to fit the model). As soon as loss for the validation set starts to show signs of overfitting, the training process can be stopped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ck8U3TUAt7rH"
      },
      "outputs": [],
      "source": [
        "nhid1 = 200\n",
        "nhid2 = 50\n",
        "def createModel(nhid1,nhid2,x_train):\n",
        "    #Start defining the input tensor:\n",
        "    inpMatrix = keras.Input(x_train.shape[1:])    # A shape tuple (integers), not including the batch size.\n",
        "\n",
        "    v = Flatten()(inpMatrix)  # convert 28x28 matrix to vector x\n",
        "\n",
        "    #create the layers and pass them the input tensor to get the output tensor:\n",
        "    hid1 = Dense(units=nhid1,\n",
        "                    activation='tanh',\n",
        "                    kernel_regularizer=keras.regularizers.l2(0.000),  # 0.002\n",
        "                    kernel_initializer='he_normal')(v)\n",
        "    hid2 = Dense(units=nhid2,\n",
        "                    activation='tanh',\n",
        "                    kernel_regularizer=keras.regularizers.l2(0.000),  # 0.002\n",
        "                    kernel_initializer='he_normal')(hid1)\n",
        "    py = Dense(units=10,\n",
        "                       kernel_initializer='he_normal',\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.000),    #0.002\n",
        "                       activation='softmax')(hid2)\n",
        "\n",
        "    #define the model's input tensors and output tensors\n",
        "    model = keras.Model(inpMatrix, py)\n",
        "    model.summary()\n",
        "    return model\n",
        "model2 = createModel(nhid1,nhid2,x_train)\n",
        "model2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=0.1), #r = learning rate\n",
        "              metrics=['accuracy'])  # acc or accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF-V_tjwt7rH"
      },
      "source": [
        "Callbacks are executed after each epoch (i.e. pass through the data). They can also be called\n",
        "`on_batch_begin` and  `on_batch_end`.\n",
        "* `EarlyStoppingStop` training when a monitored quantity has stopped improving.\n",
        "* `History` Callback that records events into a `History` object.\n",
        "* `LambdaCallback` Callback for creating simple, custom callbacks on-the-fly.\n",
        "* `LearningRateScheduler` Learning rate scheduler\n",
        "* `ModelCheckpoint` Save the model after specified epochs.\n",
        "* `ReduceLROnPlateau` Reduce learning rate when a metric has stopped improving.\n",
        "* `TensorBoard` Enable visualizations for TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS1S3Ur6t7rH"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# configure early stopping\n",
        "estop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                     patience=3)  # Stop after this number of epochs with no improvement.\n",
        "model2.fit(x_train, y_train,\n",
        "           validation_data=(x_test, y_test),\n",
        "           batch_size=100,\n",
        "           epochs=200,\n",
        "           verbose=2,\n",
        "           callbacks=[estop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPgLiM_jt7rI"
      },
      "outputs": [],
      "source": [
        "# plot history\n",
        "plot_history(model2.history.history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivG9ieomt7rI"
      },
      "source": [
        "### Build your own layer in Keras\n",
        "\n",
        "You can build your own Layers in Keras as explained [here](https://www.tensorflow.org/tutorials/customization/custom_layers).\n",
        "\n",
        "The best way to implement your own layer is extending the tf.keras.Layer class and implementing:\n",
        "\n",
        "*    `__init__` , where you can do all input-independent initialization\n",
        "*    `build`, where you know the shapes of the input tensors and can do the rest of the initialization\n",
        "*    `call`, where you do the forward computation\n",
        "\n",
        "Note that you don't have to wait until `build` is called to create your variables, you can also create them in `__init__`. However, the advantage of creating them in build is that it enables late variable creation based on the shape of the inputs the layer will operate on. On the other hand, creating variables in `__init__` would mean that shapes required to create the variables will need to be explicitly specified.\n",
        "\n",
        "The main data structure you'll work with is the `Layer`. A layer encapsulates both a state (the layer's \"weights\") and a transformation from inputs to outputs (a \"call\", the layer's forward pass).\n",
        "\n",
        "The following example is from [here](https://www.tensorflow.org/guide/keras/custom_layers_and_models). It has a state: the variables `w` and `b`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM43URPXt7rI"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "\n",
        "\n",
        "class Linear(layers.Layer):\n",
        "\n",
        "    def __init__(self, units=32, input_dim=32):\n",
        "        super(Linear, self).__init__()\n",
        "        w_init = tf.random_normal_initializer()\n",
        "        self.w = tf.Variable(initial_value=w_init(shape=(input_dim, units),\n",
        "                             dtype='float32'),\n",
        "                             trainable=True)\n",
        "        b_init = tf.zeros_initializer()\n",
        "        self.b = tf.Variable(initial_value=b_init(shape=(units,),\n",
        "                             dtype='float32'),\n",
        "                             trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k5cfOrEt7rJ"
      },
      "outputs": [],
      "source": [
        "x = tf.ones((2, 2))\n",
        "linear_layer = Linear(4, 2)\n",
        "y = linear_layer(x)\n",
        "print(y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrkJyIw7t7rJ"
      },
      "source": [
        "### Using TensorBoard for Measurements and Visualizations\n",
        "[TensorBoard](https://www.tensorflow.org/tensorboard/get_started) is a tool for providing the measurements and visualizations needed during the machine learning workflow. It enables tracking experiment metrics like loss and accuracy, visualizing the model graph, projecting embeddings to a lower dimensional space, and much more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJH-9LNGt7rK"
      },
      "outputs": [],
      "source": [
        "# Clear any logs from previous runs\n",
        "#!rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMV8lpdTt7rK"
      },
      "source": [
        "Define a simple Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFFVa0HCt7rL"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "def create_model():\n",
        "    return tf.keras.models.Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "model = create_model()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8DWKwAOt7rL"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "def train_model():\n",
        "  model = create_model()\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "  model.fit(x=x_train,\n",
        "            y=y_train,\n",
        "            epochs=5,\n",
        "            validation_data=(x_test, y_test),\n",
        "            callbacks=[tensorboard_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kjgzb3gGt7rL"
      },
      "outputs": [],
      "source": [
        "train_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "VpUzhYq75hM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63zjf3R9t7rL"
      },
      "source": [
        "Open a command window, activate the python environment and change to the current directory. Start TensorBoard through the command line or within a notebook experience.\n",
        "```\n",
        "tensorboard --logdir logs/fit\n",
        "```\n",
        "The two interfaces are generally the same. In notebooks, use the `%tensorboard` line magic. On the command line, run the same command without \"%\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrmh3PvLt7rL"
      },
      "source": [
        "**Flow Graph generated by Tensorboard**\n",
        "![Flow Graph generated by Tensorboard](img/flowGraph.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfCkyIwKt7rM"
      },
      "source": [
        "**Distribution of parameter values generated by Tensorboard**\n",
        "![Distribution](img/distribution.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN1LWxCpt7rM"
      },
      "source": [
        "**Histogram of parameter values at different epochs generated by Tensorboard**\n",
        "![Histogram](img/histogram.png)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "livereveal": {
      "scroll": "True",
      "start_slideshow_at": "selected",
      "theme": "simplePs",
      "transition": "zoom"
    },
    "nbpresent": {
      "slides": {
        "5d0ab039-9649-438a-9ea7-25c0a54307cf": {
          "id": "5d0ab039-9649-438a-9ea7-25c0a54307cf",
          "layout": "grid",
          "prev": null,
          "regions": {
            "5677b434-c42b-49ec-9c82-b0b6c0f24216": {
              "attrs": {
                "height": 0.4166666666666667,
                "pad": 0.01,
                "width": 0.9166666666666666,
                "x": 0.08333333333333333,
                "y": 0.08333333333333333
              },
              "content": {
                "cell": "42e8a721-8167-498f-bc9f-e81913335295",
                "part": "whole"
              },
              "id": "5677b434-c42b-49ec-9c82-b0b6c0f24216"
            },
            "dacdc962-390c-4b5c-a20b-6a4034c5ca0c": {
              "attrs": {
                "height": 0.4166666666666667,
                "pad": 0.01,
                "width": 0.9166666666666666,
                "x": 0.08333333333333333,
                "y": 0.5833333333333334
              },
              "id": "dacdc962-390c-4b5c-a20b-6a4034c5ca0c"
            }
          },
          "theme": null
        }
      },
      "themes": {
        "default": "68cbdb39-de1e-4cec-acd9-8e7df034b6d5",
        "theme": {
          "68cbdb39-de1e-4cec-acd9-8e7df034b6d5": {
            "id": "68cbdb39-de1e-4cec-acd9-8e7df034b6d5",
            "palette": {
              "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
                "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
                "rgb": [
                  252,
                  252,
                  252
                ]
              },
              "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
                "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
                "rgb": [
                  68,
                  68,
                  68
                ]
              },
              "50f92c45-a630-455b-aec3-788680ec7410": {
                "id": "50f92c45-a630-455b-aec3-788680ec7410",
                "rgb": [
                  155,
                  177,
                  192
                ]
              },
              "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
                "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
                "rgb": [
                  43,
                  126,
                  184
                ]
              },
              "efa7f048-9acb-414c-8b04-a26811511a21": {
                "id": "efa7f048-9acb-414c-8b04-a26811511a21",
                "rgb": [
                  25.118061674008803,
                  73.60176211453744,
                  107.4819383259912
                ]
              }
            },
            "rules": {
              "blockquote": {
                "color": "50f92c45-a630-455b-aec3-788680ec7410"
              },
              "code": {
                "font-family": "Anonymous Pro"
              },
              "h1": {
                "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
                "font-family": "Lato",
                "font-size": 8
              },
              "h2": {
                "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
                "font-family": "Lato",
                "font-size": 6
              },
              "h3": {
                "color": "50f92c45-a630-455b-aec3-788680ec7410",
                "font-family": "Lato",
                "font-size": 5.5
              },
              "h4": {
                "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
                "font-family": "Lato",
                "font-size": 5
              },
              "h5": {
                "font-family": "Lato"
              },
              "h6": {
                "font-family": "Lato"
              },
              "h7": {
                "font-family": "Lato"
              },
              "pre": {
                "font-family": "Anonymous Pro",
                "font-size": 4
              }
            },
            "text-base": {
              "font-family": "Merriweather",
              "font-size": 4
            }
          }
        }
      }
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "887px",
        "left": "0px",
        "right": "1548px",
        "top": "111px",
        "width": "212px"
      },
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}