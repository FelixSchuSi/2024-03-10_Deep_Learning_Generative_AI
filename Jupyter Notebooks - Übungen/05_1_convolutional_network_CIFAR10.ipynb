{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_WegsEfEBVe"
      },
      "source": [
        "# CNN applied to Photos in Cifar10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI4GbICmEBVe"
      },
      "source": [
        "checked 27.02.24 G.Paaß\n",
        "\n",
        "CIFAR10: Adapted from [here](https://www.tensorflow.org/tutorials/images/cnn).\n",
        "\n",
        "## Aufgaben:\n",
        "* Struktur des CNNs nachvollziehen (Graph der Units skizzieren)\n",
        "* CNN trainieren (Hyperparameter anpassen)\n",
        "* Struktur ändern:\n",
        " * Anzahl der Faltungsfilter anpassen\n",
        " * Neue Faltungsschicht (Conv-Layer) hinzufügen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJYP2eHGEBVf"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "print(\"tf-version\",tf.__version__)\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLSxkd1bEBVf"
      },
      "source": [
        "## Import Data\n",
        "The [CIFAR10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) contains 60,000 color images in 10 classes, with 6,000 images in each class. The dataset is divided into 50,000 training images and 10,000 testing images. The classes are mutually exclusive and there is no overlap between them.\n",
        "\n",
        "Here are the classes in the dataset, as well as 10 random images from each:\n",
        "\n",
        "<img src=\"img/cifar10.png\" style=\"width:600px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TIDnkuUEBVg"
      },
      "outputs": [],
      "source": [
        "# Import CIFAR10 data\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9-MbOgsEBVg"
      },
      "source": [
        "Print data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE8qN7X9EBVg"
      },
      "outputs": [],
      "source": [
        "print(\"train_images.shape\",train_images.shape,\"\\ttrain_labels.shape\",train_labels.shape)\n",
        "print(\"test_images.shape\",test_images.shape,\"\\ttest_labels.shape\",test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJ8isnArEBVg"
      },
      "outputs": [],
      "source": [
        "print(\"train_images[0]\",train_images[0].shape)\n",
        "print(\"RGB-values for one pixel\")\n",
        "print(\"train_images[0][0][0]\",train_images[0][0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkbLWNN7EBVg"
      },
      "source": [
        "To verify that the dataset looks correct, let's plot the first 25 images from the training set and display the class name below each image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4sYbq1OEBVg"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "print(\"class_names =\\n\",class_names[:5],\"\\n\",class_names[5:])\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    # The CIFAR labels happen to be arrays,\n",
        "    # which is why you need the extra index\n",
        "    plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDEsls6yEBVg"
      },
      "source": [
        "## Create the Model\n",
        "\n",
        "The 6 lines of code below define the convolutional base using a common pattern: a stack of Conv2D and MaxPooling2D layers.\n",
        "\n",
        "As input, a CNN takes tensors of shape (image_height, image_width, color_channels), ignoring the batch size. If you are new to these dimensions, color_channels refers to (R,G,B). In this example, you will configure our CNN to process inputs of shape (32, 32, 3), which is the format of CIFAR images. You can do this by passing the argument input_shape to our first layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mm4eUW78EBVg"
      },
      "outputs": [],
      "source": [
        "dropProb=0.0 # fraction of units to drop\n",
        "nfilter_1 = 32\n",
        "nfilter_2 = 64\n",
        "nfilter_3 = 64\n",
        "nhid=64\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(filters=nfilter_1, kernel_size=(3, 3),\n",
        "                        activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(rate=dropProb))\n",
        "model.add(layers.Conv2D(filters=nfilter_2, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(rate=dropProb))\n",
        "model.add(layers.Conv2D(filters=nfilter_3, kernel_size=(3, 3), activation='relu'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB6JVc0PEBVg"
      },
      "source": [
        "Let us consider the first conv2D layer with an input of 3 features. For a kernel size `(3,3)` and `nfilter_1 = 32` output feature matrices we get 896 total free parameters\n",
        "* 28 parameter per filter (896/32)\n",
        "* 1 bias-parameter per filter\n",
        "* 27 kernel parameters per filter. Hence each filter is a $3\\times3\\times3$ cube and has parameters for all of the three input features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HikHdk9lEBVg"
      },
      "source": [
        "The second layer has 32 features and  18496 parameters.\n",
        "* 289 parameter per filter (18496/64)\n",
        "* 1 bias-parameter per filter\n",
        "* 288 kernel parameters per filter. Hence each filter is a $3\\times3\\times32$ cube and has parameters for all of the 32 input features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC5YSOpsEBVh"
      },
      "source": [
        "Above, you can see that the output of every Conv2D and MaxPooling2D layer is a 3D tensor of shape (height, width, channels). The width and height dimensions tend to shrink as you go deeper in the network. The number of output channels for each Conv2D layer is controlled by the first argument (e.g., 32 or 64). Typically, as the width and height shrink, you can afford (computationally) to add more output channels in each Conv2D layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KndAhgLsEBVh"
      },
      "source": [
        "### Add fully connected Layers at the top\n",
        "To complete our model, you will feed the last output tensor from the convolutional base (of shape (4, 4, 64)) into one or more Dense layers to perform classification. Dense layers take vectors as input (which are 1D), while the current output is a 3D tensor. First, you will flatten (or unroll) the 3D output to 1D, then add one or more Dense layers on top. CIFAR has 10 output classes, so you use a final Dense layer with 10 outputs and a softmax activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Xjg_KBAEBVh"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(nhid, activation='relu'))\n",
        "model.add(layers.Dense(10))\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nHfYR_vEBVh"
      },
      "source": [
        "## Training the Model\n",
        "~ 80 sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meJT1PONEBVh"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT3Zsdk0EBVh"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK8ifu00EBVh"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZssShW9VEBVh"
      },
      "outputs": [],
      "source": [
        "train_loss, train_acc = model.evaluate(train_images,  train_labels, verbose=2)\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(\"train_acc\",train_acc)\n",
        "print(\" test_acc\",test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images[:10]"
      ],
      "metadata": {
        "id": "mrHIc3VOFeCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test10=test_images[:10,:,:,:]\n",
        "testlabels10=test_labels[:10]"
      ],
      "metadata": {
        "id": "ubb-i2c9FoIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b-XXwReBGijR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prb = model.predict(test10,   verbose=2)\n",
        "prb"
      ],
      "metadata": {
        "id": "Avqu-XQpFT8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiOhbCCJEBVh"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(test_images[i], cmap=plt.cm.binary)\n",
        "    # The CIFAR labels happen to be arrays,\n",
        "    # which is why you need the extra index\n",
        "    plt.xlabel(class_names[test_labels[i][0]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQY8iYRsEBVh"
      },
      "outputs": [],
      "source": [
        "scores=model.predict(test_images[0:10])\n",
        "nr = scores.shape[0]\n",
        "for ir in range(nr):\n",
        "  np.set_printoptions(precision=4,suppress=True)\n",
        "  prb = np.exp(scores[ir,:])/np.sum(np.exp(scores[ir,:]))\n",
        "  print(prb, test_labels[ir][0], \"{:<10}\".format(class_names[test_labels[ir][0]]), \"\\t\", test_labels[ir][0]==np.argmax(scores[ir,:]))\n",
        "  #print(test_labels[ir][0],['{:.4f}'.format(p) for p in prb])"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}